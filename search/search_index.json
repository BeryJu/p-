{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome Welcome to the p2 Documentation. p2 is an open-source Object Storage Server, focused on simple and quick sharing. It allows you to quickly share files with people. It also offers an S3-Compatible API, which allows you to easily integrate other software with p2. p2 uses the following Terminology: Storage A Storage represents a way p2 stores data. For example, this might be a LocalStorageController instance, which saves data on a locally mounted drive. There is for example also a S3StorageController class, which allows you to use S3 or an S3-compatible backend to store data. Volume Logical Groupings of data, can be compared with an S3 Bucket Component Single Features which can be enabled on a per-Volume basis. tier0 tier0 is the component which accelerates serving of your Blobs. It also allows to match custom URLs based on Regular Expressions and caches Blobs.","title":"Home"},{"location":"#welcome","text":"Welcome to the p2 Documentation. p2 is an open-source Object Storage Server, focused on simple and quick sharing. It allows you to quickly share files with people. It also offers an S3-Compatible API, which allows you to easily integrate other software with p2. p2 uses the following Terminology:","title":"Welcome"},{"location":"#storage","text":"A Storage represents a way p2 stores data. For example, this might be a LocalStorageController instance, which saves data on a locally mounted drive. There is for example also a S3StorageController class, which allows you to use S3 or an S3-compatible backend to store data.","title":"Storage"},{"location":"#volume","text":"Logical Groupings of data, can be compared with an S3 Bucket","title":"Volume"},{"location":"#component","text":"Single Features which can be enabled on a per-Volume basis.","title":"Component"},{"location":"#tier0","text":"tier0 is the component which accelerates serving of your Blobs. It also allows to match custom URLs based on Regular Expressions and caches Blobs.","title":"tier0"},{"location":"migrating-from-pyazo/","text":"Migrating from pyazo To migrate from pyazo to p2, we're going to use the S3-API to mass-import Blobs and copy a matching tier0 Policy. Prerequisites A pyazo install (any version) A full-configured p2 install (0.1.16+) Enough free Space to store all of pyazo's Blobs Check with the following command on the Server pyazo is running on du -sh /usr/share/pyazo/media Administrative shell access on the pyazo Server An API Key in p2 Recommended, but not required: A dedicated volume to import these Blobs into Preparation To migrate the data, we need the the AWS-CLI Client ( https://aws.amazon.com/cli/ ), so install it on the pyazo host as follows: sudo pip install awscli If that doesn't work for some reason, try the bundled installer: https://docs.aws.amazon.com/cli/latest/userguide/install-bundle.html To make sure it is working correctly, execute the following command to configure your account. aws configure In the prompt asking you for an AWS Access Key, input your p2 Access Key. Same goes for the Secret Access Key. When asked for a region, you can input anything, since p2 doesn't use this field currently. Now that your AWS-CLI is setup correctly, let's make sure it can interact with p2 correctly. Execute the following command, substituting p2-URL with the URL to your install. aws --endpoint-url https://<p2-URL> s3 ls The result should look something like this: 2006-02-03 16:45:09 pyazo-import-test 2006-02-03 16:45:09 some-other-volume Migrating the data To actually migrate the data, we use AWS-CLI's cp Command, which recursively copies all files. Run the following in /usr/share/pyazo/media to start the copy process: aws --endpoint-url https://<p2-URL> s3 cp . s3://<volume-name> --recursive --exclude thumbnails/ This will import all of your data into p2. You can run this command multiple times without creating duplicate objects. Migrating the URLs p2 uses a new System to allow you to use URLs of pretty much any format. By default, files will be accessible by their absolute path, e.g. https://<p2 URL>/<volume>/<blob path> This will obviously only return the file if the current user has Permissions to read the Blob. To preserve the old URLs, which match based on File Hash, you need to create one or more tier0 Policies. A tier0 Policy consists of two parts: Tags, which are used to match against the current Request, and determine when the tier0 Policy is triggered. A Blob Query, which is used to lookup a Blob from the Database based on the Request. Depending on which setting you used for default_return_view , you can create a tier0 Policy based on the table below. Setting in pyazo Tags Blob Query view_md5 serve.p2.io/match/path/relative: ([A-Fa-f0-9]{32})(\\.?[a-zA-Z0-9]*) attributes__blob.p2.io/hash/md5={path_relative}&volume__name=images view_sha512_short serve.p2.io/match/path/relative: ([A-Fa-f0-9]{16})(\\.?[a-zA-Z0-9]*) attributes__blob.p2.io/hash/sha512__startswith={path_relative}&volume__name=images view_sha256 serve.p2.io/match/path/relative: ([A-Fa-f0-9]{64})(\\.?[a-zA-Z0-9]*) attributes__blob.p2.io/hash/sha256={path_relative}&volume__name=images view_sha512 serve.p2.io/match/path/relative: ([A-Fa-f0-9]{128})(\\.?[a-zA-Z0-9]*) attributes__blob.p2.io/hash/sha512={path_relative}&volume__name=images Final Steps To finalise the migration to p2, you should take a look at the following optional components: Public Access Image-attribute Scanning","title":"Migrating from pyazo"},{"location":"migrating-from-pyazo/#migrating-from-pyazo","text":"To migrate from pyazo to p2, we're going to use the S3-API to mass-import Blobs and copy a matching tier0 Policy.","title":"Migrating from pyazo"},{"location":"migrating-from-pyazo/#prerequisites","text":"A pyazo install (any version) A full-configured p2 install (0.1.16+) Enough free Space to store all of pyazo's Blobs Check with the following command on the Server pyazo is running on du -sh /usr/share/pyazo/media Administrative shell access on the pyazo Server An API Key in p2 Recommended, but not required: A dedicated volume to import these Blobs into","title":"Prerequisites"},{"location":"migrating-from-pyazo/#preparation","text":"To migrate the data, we need the the AWS-CLI Client ( https://aws.amazon.com/cli/ ), so install it on the pyazo host as follows: sudo pip install awscli If that doesn't work for some reason, try the bundled installer: https://docs.aws.amazon.com/cli/latest/userguide/install-bundle.html To make sure it is working correctly, execute the following command to configure your account. aws configure In the prompt asking you for an AWS Access Key, input your p2 Access Key. Same goes for the Secret Access Key. When asked for a region, you can input anything, since p2 doesn't use this field currently. Now that your AWS-CLI is setup correctly, let's make sure it can interact with p2 correctly. Execute the following command, substituting p2-URL with the URL to your install. aws --endpoint-url https://<p2-URL> s3 ls The result should look something like this: 2006-02-03 16:45:09 pyazo-import-test 2006-02-03 16:45:09 some-other-volume","title":"Preparation"},{"location":"migrating-from-pyazo/#migrating-the-data","text":"To actually migrate the data, we use AWS-CLI's cp Command, which recursively copies all files. Run the following in /usr/share/pyazo/media to start the copy process: aws --endpoint-url https://<p2-URL> s3 cp . s3://<volume-name> --recursive --exclude thumbnails/ This will import all of your data into p2. You can run this command multiple times without creating duplicate objects.","title":"Migrating the data"},{"location":"migrating-from-pyazo/#migrating-the-urls","text":"p2 uses a new System to allow you to use URLs of pretty much any format. By default, files will be accessible by their absolute path, e.g. https://<p2 URL>/<volume>/<blob path> This will obviously only return the file if the current user has Permissions to read the Blob. To preserve the old URLs, which match based on File Hash, you need to create one or more tier0 Policies. A tier0 Policy consists of two parts: Tags, which are used to match against the current Request, and determine when the tier0 Policy is triggered. A Blob Query, which is used to lookup a Blob from the Database based on the Request. Depending on which setting you used for default_return_view , you can create a tier0 Policy based on the table below. Setting in pyazo Tags Blob Query view_md5 serve.p2.io/match/path/relative: ([A-Fa-f0-9]{32})(\\.?[a-zA-Z0-9]*) attributes__blob.p2.io/hash/md5={path_relative}&volume__name=images view_sha512_short serve.p2.io/match/path/relative: ([A-Fa-f0-9]{16})(\\.?[a-zA-Z0-9]*) attributes__blob.p2.io/hash/sha512__startswith={path_relative}&volume__name=images view_sha256 serve.p2.io/match/path/relative: ([A-Fa-f0-9]{64})(\\.?[a-zA-Z0-9]*) attributes__blob.p2.io/hash/sha256={path_relative}&volume__name=images view_sha512 serve.p2.io/match/path/relative: ([A-Fa-f0-9]{128})(\\.?[a-zA-Z0-9]*) attributes__blob.p2.io/hash/sha512={path_relative}&volume__name=images","title":"Migrating the URLs"},{"location":"migrating-from-pyazo/#final-steps","text":"To finalise the migration to p2, you should take a look at the following optional components: Public Access Image-attribute Scanning","title":"Final Steps"},{"location":"components/expiry/","text":"Expiry The Expiry component allows you to create Blobs which are automatically deleted at a certain date/time. To use expiry on a Blob, enable the Component on your Volume and tag the Blob with the Following tag: component.p2.io/expiry/date The value is a Unix-Timestamp. The Blob will be deleted as soon as the time has been reached.","title":"Expiry"},{"location":"components/expiry/#expiry","text":"The Expiry component allows you to create Blobs which are automatically deleted at a certain date/time. To use expiry on a Blob, enable the Component on your Volume and tag the Blob with the Following tag: component.p2.io/expiry/date The value is a Unix-Timestamp. The Blob will be deleted as soon as the time has been reached.","title":"Expiry"},{"location":"components/image-attribute-scanning/","text":"Image-attribute Scanning The Image Attribute Scanning Component scans and extracts EXIF Data from compatible images (jpeg and tiff). The following attributes are currently extracted: Image Height Image Width Compression Orientation Camera Model Software","title":"Image-attribute Scanning"},{"location":"components/image-attribute-scanning/#image-attribute-scanning","text":"The Image Attribute Scanning Component scans and extracts EXIF Data from compatible images (jpeg and tiff). The following attributes are currently extracted: Image Height Image Width Compression Orientation Camera Model Software","title":"Image-attribute Scanning"},{"location":"components/public-access/","text":"Public Access Public Access automatically enables Anonymous Read access to all new Blobs in the current Volume.","title":"Public Access"},{"location":"components/public-access/#public-access","text":"Public Access automatically enables Anonymous Read access to all new Blobs in the current Volume.","title":"Public Access"},{"location":"components/quota/","text":"Quota Quota allows you to limit he Size of a Volume. You can configure a size threshold and an action which p2 will execute. Currently supported actions are: Do Nothing Shows warning in UI No alerts Prevent Further Uploads Prevents new Uploads to Volume Existing Blobs can still be updated Warning in UI is still shown Send E-Mail to uploader and admin A Warning E-Mail will be sent to the User uploading the Blob and all Admins as well. Warning in UI is still shown.","title":"Quota"},{"location":"components/quota/#quota","text":"Quota allows you to limit he Size of a Volume. You can configure a size threshold and an action which p2 will execute. Currently supported actions are: Do Nothing Shows warning in UI No alerts Prevent Further Uploads Prevents new Uploads to Volume Existing Blobs can still be updated Warning in UI is still shown Send E-Mail to uploader and admin A Warning E-Mail will be sent to the User uploading the Blob and all Admins as well. Warning in UI is still shown.","title":"Quota"},{"location":"components/replication/","text":"Replication The replication Component replicates Blobs from one Volume to another. This happens in a push-method, rather than pull. This feature is under development and might not behave as you imagine it. You can optionally specify an offset by which Operations will be delayed, making it possible to use this as a backup. You can also ignore Blobs matching a certain pattern, for example only replicate files matching not .iso","title":"Replication"},{"location":"components/replication/#replication","text":"The replication Component replicates Blobs from one Volume to another. This happens in a push-method, rather than pull. This feature is under development and might not behave as you imagine it. You can optionally specify an offset by which Operations will be delayed, making it possible to use this as a backup. You can also ignore Blobs matching a certain pattern, for example only replicate files matching not .iso","title":"Replication"},{"location":"installation/install/","text":"Installation This guide expects you to have a fully-configured Kubernetes cluster. If you want to run p2 on a single server, read this first. Operator p2 uses an operator to manage itself. Execute kubectl apply -f https://git.beryju.org/BeryJu.org/p2/raw/master/deploy/operator.yaml to install the Operator. To verify that the operator has successfully been installed and is running, check the output of kubectl get pod . NAME READY STATUS RESTARTS AGE p2-operator-5bc6bcf5c7-qtsp2 1/1 Running 0 98s Instance Now to create the actual p2 instance, download the example instance definition and change it to your needs. After you've change the YAML to your liking, create the instance with the following command: kubectl apply -f example-instance.yaml The actually bootstrapping of the instance can take a few minutes. Run this command to watch the progress: watch kubectl get pods Once the output looks something like this, your p2 install is ready to use. NAME READY STATUS RESTARTS AGE example-p2-18vtwme7xxcdin9copwgnnz13-grpc-b76c8b87c-jhv98 1/1 Running 0 10m example-p2-18vtwme7xxcdin9copwgnnz13-postgresql-0 1/1 Running 0 10m example-p2-18vtwme7xxcdin9copwgnnz13-redis-master-0 1/1 Running 0 10m example-p2-18vtwme7xxcdin9copwgnnz13-redis-slave-776bd5569h7ttx 1/1 Running 0 10m example-p2-18vtwme7xxcdin9copwgnnz13-static-659f977dc4-8sx5m 2/2 Running 0 10m example-p2-18vtwme7xxcdin9copwgnnz13-tier0-77f7694798-4d776 1/1 Running 0 10m example-p2-18vtwme7xxcdin9copwgnnz13-tier0-77f7694798-f5tc9 1/1 Running 0 10m example-p2-18vtwme7xxcdin9copwgnnz13-web-77f44bd466-ngslj 1/1 Running 0 10m example-p2-18vtwme7xxcdin9copwgnnz13-worker-6c69d985b-l8vdd 1/1 Running 0 10m p2-operator-5bc6bcf5c7-qtsp2 1/1 Running 0 34m Access your p2 install under the domain(s) configured. The default login credentials are admin/admin .","title":"Installation"},{"location":"installation/install/#installation","text":"This guide expects you to have a fully-configured Kubernetes cluster. If you want to run p2 on a single server, read this first.","title":"Installation"},{"location":"installation/install/#operator","text":"p2 uses an operator to manage itself. Execute kubectl apply -f https://git.beryju.org/BeryJu.org/p2/raw/master/deploy/operator.yaml to install the Operator. To verify that the operator has successfully been installed and is running, check the output of kubectl get pod . NAME READY STATUS RESTARTS AGE p2-operator-5bc6bcf5c7-qtsp2 1/1 Running 0 98s","title":"Operator"},{"location":"installation/install/#instance","text":"Now to create the actual p2 instance, download the example instance definition and change it to your needs. After you've change the YAML to your liking, create the instance with the following command: kubectl apply -f example-instance.yaml The actually bootstrapping of the instance can take a few minutes. Run this command to watch the progress: watch kubectl get pods Once the output looks something like this, your p2 install is ready to use. NAME READY STATUS RESTARTS AGE example-p2-18vtwme7xxcdin9copwgnnz13-grpc-b76c8b87c-jhv98 1/1 Running 0 10m example-p2-18vtwme7xxcdin9copwgnnz13-postgresql-0 1/1 Running 0 10m example-p2-18vtwme7xxcdin9copwgnnz13-redis-master-0 1/1 Running 0 10m example-p2-18vtwme7xxcdin9copwgnnz13-redis-slave-776bd5569h7ttx 1/1 Running 0 10m example-p2-18vtwme7xxcdin9copwgnnz13-static-659f977dc4-8sx5m 2/2 Running 0 10m example-p2-18vtwme7xxcdin9copwgnnz13-tier0-77f7694798-4d776 1/1 Running 0 10m example-p2-18vtwme7xxcdin9copwgnnz13-tier0-77f7694798-f5tc9 1/1 Running 0 10m example-p2-18vtwme7xxcdin9copwgnnz13-web-77f44bd466-ngslj 1/1 Running 0 10m example-p2-18vtwme7xxcdin9copwgnnz13-worker-6c69d985b-l8vdd 1/1 Running 0 10m p2-operator-5bc6bcf5c7-qtsp2 1/1 Running 0 34m Access your p2 install under the domain(s) configured. The default login credentials are admin/admin .","title":"Instance"},{"location":"installation/single-node-install/","text":"Single-Node Installation Since p2 is built with Kubernetes integration, the only supported method to run p2 is within such a cluster. To run p2 on a single node, it is recommended to use k3s . This page is a short guide on how to prepare your single node for p2. Requirements Hardware Without tier0 With tier0 CPU 2 Cores 2 Cores RAM 2 GB 4 GB Disk At least 20 GB recommended + your data Installing k3s Installing k3s is very easy. Simply run the following script on your node to install the Cluster. curl -sfL https://get.k3s.io | sh - After the script is done, you should be able to run kubectl get node and see one ready node: NAME STATUS ROLES AGE VERSION p2-test-vm Ready master 13s v1.14.5-k3s.1 Congratulations, you now have a single-node Kubernetes cluster. By default, k3s installs traefik as Ingress Controller (= Reverse Proxy). There is however no default Persistent Volume Provisioner, which means we need the following component: Installing local-path-provisioner This tool allows Kubernetes to dynamically allocate \"Volumes\", pointing to a local path. Download the install-manifest as following: wget https://raw.githubusercontent.com/rancher/local-path-provisioner/master/deploy/local-path-storage.yaml The default base-path is /opt/local-path-provisioner . If you wish to change that path, edit the manifest to your needs. Once you're done, apply the manifest with this command: kubectl apply -f local-path-storage.yaml . To check that the provisioner has successfully been installed and is running, execture kubectl -n local-path-storage get pod . The output should look something like this: NAME READY STATUS RESTARTS AGE local-path-provisioner-848fdcff-h4l68 1/1 Running 0 10s By default, the local-path-provisioner is not set as default. To change that, run kubectl patch storageclass local-path -p '{\"metadata\": {\"annotations\":{\"storageclass.kubernetes.io/is-default-class\":\"true\"}}}' Now that you have a fully-prepared Kubernetes cluster, you can continue with the normal Installation instructions here","title":"Single-Node Installation"},{"location":"installation/single-node-install/#single-node-installation","text":"Since p2 is built with Kubernetes integration, the only supported method to run p2 is within such a cluster. To run p2 on a single node, it is recommended to use k3s . This page is a short guide on how to prepare your single node for p2.","title":"Single-Node Installation"},{"location":"installation/single-node-install/#requirements","text":"","title":"Requirements"},{"location":"installation/single-node-install/#hardware","text":"Without tier0 With tier0 CPU 2 Cores 2 Cores RAM 2 GB 4 GB Disk At least 20 GB recommended + your data","title":"Hardware"},{"location":"installation/single-node-install/#installing-k3s","text":"Installing k3s is very easy. Simply run the following script on your node to install the Cluster. curl -sfL https://get.k3s.io | sh - After the script is done, you should be able to run kubectl get node and see one ready node: NAME STATUS ROLES AGE VERSION p2-test-vm Ready master 13s v1.14.5-k3s.1 Congratulations, you now have a single-node Kubernetes cluster. By default, k3s installs traefik as Ingress Controller (= Reverse Proxy). There is however no default Persistent Volume Provisioner, which means we need the following component:","title":"Installing k3s"},{"location":"installation/single-node-install/#installing-local-path-provisioner","text":"This tool allows Kubernetes to dynamically allocate \"Volumes\", pointing to a local path. Download the install-manifest as following: wget https://raw.githubusercontent.com/rancher/local-path-provisioner/master/deploy/local-path-storage.yaml The default base-path is /opt/local-path-provisioner . If you wish to change that path, edit the manifest to your needs. Once you're done, apply the manifest with this command: kubectl apply -f local-path-storage.yaml . To check that the provisioner has successfully been installed and is running, execture kubectl -n local-path-storage get pod . The output should look something like this: NAME READY STATUS RESTARTS AGE local-path-provisioner-848fdcff-h4l68 1/1 Running 0 10s By default, the local-path-provisioner is not set as default. To change that, run kubectl patch storageclass local-path -p '{\"metadata\": {\"annotations\":{\"storageclass.kubernetes.io/is-default-class\":\"true\"}}}' Now that you have a fully-prepared Kubernetes cluster, you can continue with the normal Installation instructions here","title":"Installing local-path-provisioner"}]}